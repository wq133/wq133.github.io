---
layout: post
title: Java-JVM总结
subtitle: JVM内存区域、GC机制、类加载器
date: 2024-01-21
author: Wu
header-img: ../article_img/kb_3.jpg
catalog: true
tags:
  - Java
  - 八股文
---
## 1.Arraylist 和 linkedlist的 区别

共同点：
1. 元素可以重复
2. 有索引
3. 元素有序
4. 线程不安全、效率高

不同点：
- ArrayList的底层数据结构是Object数组（动态数组）；LinkedList的底层数据结构是双向链表
- 插入和删除是否受元素位置的影响：
**`ArrayList` 采用数组存储，所以插入和删除元素的时间复杂度受元素位置的影响。** 
`LinkedList` 采用链表存储，所以在头尾插入或者删除元素不受元素位置的影响。

ArrayList比如：执行`add(E e)`方法的时候， `ArrayList` 会默认在将指定的元素追加到此列表的末尾，这种情况时间复杂度就是 O(1)；但是如果要在指定位置 i 插入和删除元素的话（`add(int index, E element)`），时间复杂度就为 O(n)。
因为在进行上述操作的时候集合中第 i 和第 i 个元素之后的(n-i)个元素都要执行向后位/向前移一位的操作。

LinkedList中 `add(E e)`、`addFirst(E e)`、`addLast(E e)`、`removeFirst()`、 `removeLast()`，时间复杂度为 O(1)，如果是要在指定位置 `i` 插入和删除元素的话（`add(int index, E element)`，`remove(Object o)`,`remove(int index)`）， 时间复杂度为 O(n) ，因为需要先移动到指定位置再插入和删除。

- 是否支持快速随机访问：`LinkedList` 不支持高效的随机元素访问，而 `ArrayList`（实现了 `RandomAccess` 接口） 支持。快速随机访问就是通过元素的序号快速获取元素对象(对应于`get(int index)`方法)。

- 内存空间占用： `ArrayList` 的空间浪费主要体现在在 list 列表的结尾会预留一定的容量空间，而 LinkedList 的空间花费则体现在它的每一个元素都需要消耗比 ArrayList 更多的空间（因为要存放直接后继和直接前驱以及数据）。

精炼：

- ArrayList基于数组实现，LinkedList基于链表实现 
- ArryList适合随机查找，LinkedList适合增删，时间复杂度不同 
- ArrayList和LinkedList都是基于List接⼝实现的，LinkedList还实现了 Deque接⼝，可以当做队列使⽤
- 扩容操作：ArrayList的初始化数组默认⻓度10，当添加元素时，如果数组已满，则创建一个容量是原数组容量 1.5倍的新数组，并将原数组中的元素复制到新数组中。新元素添加到新数组的末尾。

这个过程保证了 `ArrayList` 在大多数情况下的添加操作是常量时间的，但在需要扩容时，会有一次线性时间的复制操作。

![[../../article_img/CollectionApi_relation.png]]
## 2.Hashmap
![[../../article_img/MapApi.png]]
### 基础特点
1.无序
2.无索引
3.key唯一value可以重复
4.线程不安全
5.数据结构：数组+链表+红黑树（java8）
6.扩容HashMap、ConcurrentHashMap的数组默认⻓度16，2倍数组扩 容，扩容通过开辟新数组进⾏转移⽼数组元素
### 底层实现原理/1.7和1.8的区别  

精炼：

- HashMap在JDK 7采⽤的是 数组 + 链表 的⽅式，由于HashMap的key 是基于hash值计算后放到对应的数组槽位的，可能会出现hash碰 撞，所以在每个槽位采⽤链表头插法进⾏存放元素，如果容量不⾜会 先扩容 
- HashMap在JDK 8采⽤的是 数组 + 链表/红⿊树 的⽅式，基于JDK 7的 基础上为了解决链表过⻓，导致 **查询效率降低以及头插法导致循环链表** ，从⽽死循环造成CPU满载的问题，所以JDK 8采⽤了尾插法。

细致：

- 数组元素类型不同：JDK1.8 HashMap数组元素类型为`Node<K,V>`，JDK1.7 HashMap数组元素类型为`Entry<K,V>`：｜实际就是换了个类名，并没有什么本质不同。

- 数据结构不同：JDK1.7 HashMap 底层是 **数组和链表** 结合在一起使用也就是 **链表散列**。JDK1.8后HashMap底层为数组+链表或红黑树。

- hash计算规则不同；JDK 1.8 的 hash 方法 相比于 JDK 1.7 hash 方法更加简化，但是原理不变。相比于 JDK1.8 的 hash 方法 ，JDK 1.7 的 hash 方法的性能会稍差一点。
```java
static int hash(int h) {
	h ^= (h >>> 20) ^ (h >>> 12);
    return h ^ (h >>> 7) ^ (h >>> 4);
}

// 而在JDK 1.8中，`hash()`方法的实现被简化为：
static final int hash(Object key) {
	int h;
	return (key == null) ? 0 : (h = key.hashCode()) ^ (h >>> 16);
}
```

- put操作不同；JDK1.7并没有使用红黑树，如果哈希冲突后，都用链表解决。区别于JDK1.8的尾部插入，JDK1.7采用头部插入的方式：（就是最后插入的在链表前。）

```
public V put(K key, V value) {     
    // 键为null，将元素放置到table数组的0下标处  
    if (key == null)    
        return putForNullKey(value);   
    // 计算hash和数组下标索引位置  
    int hash = hash(key.hashCode());    
    int i = indexFor(hash, table.length);    
    // 遍历链表，当key一致时，说明该key已经存在，使用新值替换旧值并返回  
    for (Entry<K,V> e = table[i]; e != null; e = e.next) {    
        Object k;    
        if (e.hash == hash && ((k = e.key) == key || key.equals(k))) {    
            V oldValue = e.value;    
            e.value = value;    
            e.recordAccess(this);    
            return oldValue;    
        }    
    }    
      
    modCount++;  
    // 插入链表  
    addEntry(hash, key, value, i);    
    return null;    
}   
  
private V putForNullKey(V value) {   
    // 一样的，新旧值替换  
    for (Entry<K,V> e = table[0]; e != null; e = e.next) {    
        if (e.key == null) {    
            V oldValue = e.value;    
            e.value = value;    
            e.recordAccess(this);    
            return oldValue;    
        }    
    }    
      
    modCount++;    
    // 插入到数组下标为0位置  
    addEntry(0, null, value, 0);    
    return null;    
}   
  
void addEntry(int hash, K key, V value, int bucketIndex) {  
    // 新值头部插入，原先头部变成新的头部元素的next  
    Entry<K, V> e = table[bucketIndex];  
    table[bucketIndex] = new Entry<K, V>(hash, key, value, e);  
    // 计数，扩容  
    if (size++ >= threshold)  
        resize(2 * table.length);  
}
```

在JDK1.8以后，由头插法改成了尾插法，因为头插法还存在一个死链的问题。

- 扩容机制不一样

JDK1.7

1. 触发扩容的条件：在 JDK 1.7 中，HashMap 的扩容是在达到阈值（`threshold`）时触发的。阈值是指 当前容量（`capacity`）乘以加载因子（`loadFactor`）。

2. 扩容方式：扩容时，HashMap 会创建一个新的数组，将原有的键值对重新散列到新的数组中。这个过程需要锁住整个 HashMap，因此 **在扩容期间，其他线程无法进行读写操作** ，可能会导致性能瓶颈。

3. 重新计算了每个元素的哈希值，按旧链表的正序遍历链表、在新链表的头部依次插入，**即在转移数据、扩容后，容易出现链表逆序的情况。**

JDK1.8 

1. 在默认的数组长度是16，存在一个默认的负载因子（也就是临界值），如果数组长度达到16*0.75 = 12 就会扩容成32。
2. 链的长度大于8且数组长度大于64的时候，就会将链表转换红黑树。如果只是链表长度大于8但是数组长度小于64的时候，`HashMap.Entry` 类型的链表节点在链表长度达到一定程度时会被替换为 `TreeNode`，链表就转化为红黑树，以减少搜索时间。这样可以加速在链表上的查找和插入操作。这种改进减小了链表长度，提高了查找效率。

- 扩容的并发改进： JDK 1.8 对于扩容的并发性做了改进，使用了更加细粒度的锁机制。
这样，在进行扩容时，不再需要锁住整个 HashMap，而是只锁住当前正在处理的桶，提高了并发性。

### 链表和红黑树的时间复杂度对比

除了添加元素外，查询和删除效率比链表快

1. 红黑树查询、增加和删除的时间复杂度：O(log2n)

2. 链表的查询和删除的时间复杂度： O(n)，插入为：O(1)

### 为什么HashMap使用红黑树而不是AVL树
1. 红黑树和AVL树都是常见的平衡二叉树，它们的查找，删除，修改的时间复杂度都是 O(log n)
2. 红黑树相比于AVL树，它的插入更快。
3. AVL树和红黑树相比有以下的区别:
- AVL树是更加严格的平衡，因此可以提供更快的查找速度，一般读取查找密集型任务，适用AVL树
- 红黑树更适合插入修改密集型任务
- 通常，AVL树的旋转比红黑树的旋转更加难以平衡和调试


### 线程不安全的原因（考察HashMap和HashTable的区别）
多线程下可能会出现并发问题，HashMap中的方法没有被Sychronize修饰
而HashTable线程安全。
HashMap允许Null键null值，而HashTable不允许

### 怎么扩容

### 底层数组大小为什么是2^n / HashMap 的长度为什么是 2 的幂次方？

为了能让 HashMap 存取高效，尽量较少碰撞，也就是要尽量把数据分配均匀。
我们上面也讲到了过了，Hash 值的范围值-2147483648 到 2147483647，前后加起来大概 40 亿的映射空间，只要哈希函数映射得比较均匀松散，一般应用是很难出现碰撞的。
但问题是一个 40 亿长度的数组，内存是放不下的。所以这个散列值是不能直接拿来用的。用之前还要先做对数组的长度取模运算，得到的余数才能用来要存放的位置也就是对应的数组下标。这个数组下标的计算方法是“ `(n - 1) & hash`”。（n 代表数组长度，&位与运算）。
这也就解释了 HashMap 的长度为什么是 2 的幂次方。

### 扩容死锁产生的过程
JDK1.7 及之前版本的 `HashMap` 在多线程环境下扩容操作可能存在死循环问题，这是由于当一个桶位中有多个元素需要进行扩容时，多个线程同时对链表进行操作，头插法可能会导致链表中的节点指向错误的位置，从而形成一个环形链表，进而使得查询元素的操作陷入死循环无法结束。

为了解决这个问题，JDK1.8 版本的 HashMap 采用了尾插法而不是头插法来避免链表倒置，使得插入的节点永远都是放在链表的末尾，避免了链表中的环形结构。但是还是不建议在多线程下使用 `HashMap`，因为多线程下使用 `HashMap` 还是会存在数据覆盖的问题。并发环境下，推荐使用 `ConcurrentHashMap` 。

## 3.Concurrenthashmap

### 实现原理

JDK1.7中是由Segment数组（类似HashMap的结构所以每一个 `HashMap` 的内部可以进行扩容），Segment默认最多个数是16，一旦确认不能更改，默认支持最多 16 个线程并发。
Java7 中 `ConcurrentHashMap` 使用的分段锁，也就是每一个 Segment 上同时只有一个线程可以操作，每一个 `Segment` 都是一个类似 `HashMap` 数组的结构，它可以扩容，它的冲突会转化为链表。但是 `Segment` 的个数一但初始化就不能改变。

Java8 中的 `ConcurrentHashMap` 使用的 `Synchronized` 锁 + CAS 的机制。结构也由 Java7 中的 **`Segment` 数组 + `HashEntry` 数组 + 链表** 进化成了 **Node 数组 + 链表 / 红黑树**，Node 是类似于一个 HashEntry 的结构。它的冲突再达到一定大小时会转化成红黑树，在冲突小于一定数量时又退回链表。

### 为什么线程安全

 在JDK8中,ConcurrentHashMap的底层数据结构与HashMap一样,也是采用“数组+链表+红黑树”的形式。同时,它又采用锁定头节点的方式降低了锁粒度,以较低的性能代价实现了线程安全。底层数据结构的逻辑可以参考HashMap的实现,它的线程安全的实现机制如下：
 
  1. 初始化数组或头节点时,ConcurrentHashMap并没有加锁,而是CAS的方式进行原子替换（原子操作,基于Unsafe类的原子操作API）。 
  2. 插入数据时会进行加锁处理,但锁定的不是整个数组,而是槽中的头节点。所以,ConcurrentHashMap中锁的粒度是槽,而不是整个数组,并发的性能很好。
  3. 扩容时会进行加锁处理,锁定的仍然是头节点。并且,支持多个线程同时对数组扩容,提高并发能力。每个线程需先以CAS操作抢任务,争抢一段连续槽位的数据转移权。抢到任务后,该线程会锁定槽内的头节点,然后将链表或树中的数据迁移到新的数组里。
  4. 查找数据时并不会加锁,所以性能很好。另外,在扩容的过程中,依然可以支持查找操作。  如果某个槽还未进行迁移,则直接可以从旧数组里找到数据。如果某个槽已经迁移完毕,但是整个扩容还没结束,则扩容线程会创建一个转发节点存入旧数组,届时查找线程根据转发节点的提示,从新数组中找到目标数据。
  
  加分回答：
  
  ConcurrentHashMap实现线程安全的难点在于多线程并发扩容,
  即当一个线程在插入数据时,若发现数组正在扩容,那么它就会立即参与扩容操作,完成扩容后再插入数据到新数组。在扩容的时候,多个线程共同分担数据迁移任务,每个线程负责的迁移数量是 `(数组长度 。>> 3) / CPU核心数`。 
  
  也就是说,为线程分配的迁移任务,是充分考虑了硬件的处理能力的。多个线程依据硬件的处理能力,平均分摊一部分槽的迁移工作。
  
  另外,如果计算出来的迁移数量小于16,则强制将其改为16,这是考虑到目前服务器领域主流的CPU运行速度,每次处理的任务过少,对于CPU的算力也是一种浪费。

### 分段锁怎么实现  

在JDK 7下，采⽤分段锁的⽅式来保证线程安全，内部维护了⼀个 segment数组，每个segment都包含了⼀个HashEntry数组，相当于⼀ 个⼩的HashMap提供了get、put⽅法，并且segment都实现了 ReentrantLock，put元素时通过ReentrantLock加锁 

在JDK 8下，采⽤synchronized来保证线程安全的，内部维护⼀个 Node数组，put元素时对Node节点进⾏加锁，相当于JDK 7减⼩了锁 的粒度并且节省了内存

## CopyOnWriteList 
写时复制
- CopyOnWriteArrayList是基于数组实现的，采⽤多写分离的⽅式来应 对多线程的读写操作：当对内部数组进⾏操作时，会拷⻉⼀份出来⽤ 于写，写操作时会进⾏加锁避免并发写⼊导致数据丢失，⽽读依旧在；旧数组进⾏，当操作完之后，再将引⽤重新指向新数组完成整个操作
- CopyOnWriteArrayList适合**读多写少**的场景，但是⽐较吃内存，并且 对于实时性要求很⾼场景不太适⽤因为可能读到旧数据。

### 怎么保证线程安全，为什么这么做？
add源码分析：
- `add`方法内部用到了 `ReentrantLock` 加锁，保证了同步，避免了多线程写的时候会复制出多个副本出来。锁被修饰保证了锁的内存地址肯定不会被修改，并且，释放锁的逻辑放在 `finally` 中，可以保证锁能被释放。
- `CopyOnWriteArrayList` 通过复制底层数组的方式实现写操作，即先创建一个新的数组来容纳新添加的元素，然后在新数组中进行写操作，最后将新数组赋值给底层数组的引用，替换掉旧的数组
为什么这么做？
- `CopyOnWriteArrayList` 线程安全的核心在于其采用了 **写时复制（Copy-On-Write）** 的策略。
- 每次写操作都需要通过 `Arrays.copyOf` 复制底层数组，时间复杂度是 O(n) 的，且会占用额外的内存空间。因此，`CopyOnWriteArrayList` 适用于读多写少的场景，在写操作不频繁且内存资源充足的情况下，可以提升系统的性能表现。
- `CopyOnWriteArrayList` 中并没有类似于 `ArrayList` 的 `grow()` 方法扩容的操作。


## 快速失败(fast fail) 
快速失败是Java基于多线程操作同⼀集合的保护机制 解决办法 可以使⽤Colletions.synchronizedList⽅法处理集合 或 在修改集合 的地⽅⽤synchronized进⾏修饰，但是性能较低 使⽤CopyOnWriteArrayList代替List，采⽤读写分离的⽅式，写时 会新拷⻉⼀份数组，对新数组进⾏操作，操作完之后，再将引⽤ 指向新数组